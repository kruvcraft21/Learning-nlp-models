{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1221a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_equal: True\n",
      "allclose   : True\n",
      "||diff||   : 0.0\n",
      "cosine     : 1.0\n",
      "OK: embedding для 'I' совпадает в обоих предложениях (Word2Vec — статическая модель).\n"
     ]
    }
   ],
   "source": [
    "# Установка gensim при необходимости\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Два предложения\n",
    "sentences = [\n",
    "    [\"I\", \"like\", \"machine\", \"learning\"],\n",
    "    [\"I\", \"want\", \"to\", \"eat\", \"soup\"],\n",
    "]\n",
    "\n",
    "# Обучаем небольшую Word2Vec-модель\n",
    "model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=50,\n",
    "    window=2,\n",
    "    min_count=1,\n",
    "    sg=1,          # skip-gram\n",
    "    workers=1,\n",
    "    epochs=100,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Для Word2Vec один и тот же словарный токен имеет один и тот же вектор\n",
    "emb_in_s1 = model.wv[\"I\"]\n",
    "emb_in_s2 = model.wv[\"I\"]\n",
    "\n",
    "# Проверка совпадения\n",
    "print(\"array_equal:\", np.array_equal(emb_in_s1, emb_in_s2))\n",
    "print(\"allclose   :\", np.allclose(emb_in_s1, emb_in_s2))\n",
    "print(\"||diff||   :\", np.linalg.norm(emb_in_s1 - emb_in_s2))\n",
    "\n",
    "# Дополнительно косинусная близость (должна быть 1.0)\n",
    "cos = float(np.dot(emb_in_s1, emb_in_s2) / (np.linalg.norm(emb_in_s1) * np.linalg.norm(emb_in_s2)))\n",
    "print(\"cosine     :\", cos)\n",
    "\n",
    "assert np.allclose(emb_in_s1, emb_in_s2), \"Векторы 'I' отличаются, что не ожидается для Word2Vec.\"\n",
    "print(\"OK: embedding для 'I' совпадает в обоих предложениях (Word2Vec — статическая модель).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad56d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_equal: False\n",
      "allclose   : False\n",
      "||diff||   : 6.0129676\n",
      "cosine     : 0.9002635478973389\n",
      "OK: ELMo даёт разные контекстные embedding для 'I' в этих предложениях.\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# Установка зависимостей при необходимости и импорт\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "# Загружаем ELMo (указываем signature и output_key в конструкторе слоя)\n",
    "elmo = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/elmo/3\",\n",
    "    signature=\"default\",\n",
    "    output_key=\"elmo\",\n",
    "    trainable=False,\n",
    ")\n",
    "\n",
    "# Два предложения\n",
    "s1 = \"I like machine learning\"\n",
    "s2 = \"I want to eat soup\"\n",
    "\n",
    "# Получаем ELMo-эмбеддинги (batch=1, seq_len, 1024)\n",
    "emb1 = elmo(tf.constant([s1]))[0].numpy()\n",
    "emb2 = elmo(tf.constant([s2]))[0].numpy()\n",
    "\n",
    "# Простейшая токенизация по пробелам, чтобы найти позицию \"I\"\n",
    "tokens1 = s1.split()\n",
    "tokens2 = s2.split()\n",
    "idx1 = tokens1.index(\"I\")\n",
    "idx2 = tokens2.index(\"I\")\n",
    "\n",
    "v1 = emb1[idx1]\n",
    "v2 = emb2[idx2]\n",
    "\n",
    "# Сравнение\n",
    "print(\"array_equal:\", np.array_equal(v1, v2))\n",
    "print(\"allclose   :\", np.allclose(v1, v2))\n",
    "print(\"||diff||   :\", np.linalg.norm(v1 - v2))\n",
    "cos = float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "print(\"cosine     :\", cos)\n",
    "\n",
    "assert not np.allclose(v1, v2), \"Ожидалось, что ELMo даст разные (контекстные) векторы для 'I' в разных предложениях.\"\n",
    "print(\"OK: ELMo даёт разные контекстные embedding для 'I' в этих предложениях.\")\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
